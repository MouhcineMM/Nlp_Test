{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1f8281",
   "metadata": {},
   "source": [
    "# Chargement des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79cb90",
   "metadata": {},
   "source": [
    "**AG News Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80651f",
   "metadata": {},
   "source": [
    "Représente 130 000 articles réparties en 4 catégories différentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2250620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlyle Looks Toward Commercial Aerospace (Reuters) : Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[3 4 2 1]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(r\"Dataset\\AG_classif\\AG_class_train.csv\", header=0)\n",
    "df_test = pd.read_csv(r\"Dataset\\AG_classif\\AG_class_test.csv\", header=0)\n",
    "\n",
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Name_category : 1-World, 2-Sports, 3-Business, 4-Sci/Technology\n",
    "\n",
    "df1 = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "x1 = df1.iloc[:,2]\n",
    "y1 = df1.iloc[:,0]\n",
    "\n",
    "x1 = df1.iloc[:, 1].astype(str) + \" : \" + x1.astype(str)\n",
    "print(x1[1])\n",
    "str(y1.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442325af",
   "metadata": {},
   "source": [
    "**DBpedia Ontology**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf83ec",
   "metadata": {},
   "source": [
    "Dataset référent des pages wikipédia avec plus de 219 classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c066cf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1917 Bali earthquake occurred at 06:50 local time on 21 January (23:11 on 20 January UTC). It had an estimated magnitude of 6.6 on the surface wave magnitude scale and had a maximum perceived intensity of IX (Violent) on the Mercalli intensity scale. It caused widespread damage across Bali, particularly in the south of the island. It triggered many landslides, which caused 80% of the 1500 casualties.\n",
      "['Earthquake' 'SolarEclipse' 'MusicFestival' 'MilitaryConflict'\n",
      " 'FilmFestival' 'Convention' 'FootballMatch' 'OlympicEvent' 'GrandPrix'\n",
      " 'GolfTournament' 'WomensTennisAssociationTournament' 'TennisTournament'\n",
      " 'SoccerTournament' 'WrestlingEvent' 'HorseRace' 'CyclingRace'\n",
      " 'MixedMartialArtsEvent' 'Election' 'SoccerClubSeason'\n",
      " 'NationalFootballLeagueSeason' 'NCAATeamSeason' 'BaseballSeason'\n",
      " 'VideoGame' 'BiologicalDatabase' 'EurovisionSongContestEntry' 'Album'\n",
      " 'Musical' 'ClassicalMusicComposition' 'ArtistDiscography' 'Single' 'Poem'\n",
      " 'Magazine' 'Newspaper' 'AcademicJournal' 'Play' 'Manga' 'ComicStrip'\n",
      " 'Anime' 'HollywoodCartoon' 'MusicGenre' 'Grape' 'Conifer' 'Fern' 'Moss'\n",
      " 'GreenAlga' 'CultivatedVariety' 'Cycad' 'Arachnid' 'Fish' 'Insect'\n",
      " 'Reptile' 'Mollusca' 'Bird' 'Amphibian' 'RaceHorse' 'Crustacean' 'Fungus'\n",
      " 'Lighthouse' 'Theatre' 'RollerCoaster' 'Airport' 'RailwayStation' 'Road'\n",
      " 'RailwayLine' 'Bridge' 'RoadTunnel' 'Dam' 'CricketGround' 'Stadium'\n",
      " 'Racecourse' 'GolfCourse' 'Prison' 'Hospital' 'Museum' 'Hotel' 'Library'\n",
      " 'Restaurant' 'ShoppingMall' 'HistoricBuilding' 'Castle' 'Volcano'\n",
      " 'MountainPass' 'Glacier' 'Canal' 'River' 'Lake' 'Mountain' 'Cave'\n",
      " 'MountainRange' 'Galaxy' 'ArtificialSatellite' 'Planet' 'Town' 'Village'\n",
      " 'Diocese' 'AutomobileEngine' 'SupremeCourtOfTheUnitedStatesCase'\n",
      " 'MilitaryPerson' 'Religious' 'Engineer' 'BusinessPerson'\n",
      " 'SportsTeamMember' 'SoccerManager' 'Chef' 'Philosopher' 'CollegeCoach'\n",
      " 'ScreenWriter' 'Historian' 'Poet' 'President' 'PrimeMinister'\n",
      " 'Congressman' 'Senator' 'Mayor' 'MemberOfParliament' 'Governor' 'Monarch'\n",
      " 'PlayboyPlaymate' 'Cardinal' 'Saint' 'Pope' 'ChristianBishop'\n",
      " 'BeautyQueen' 'RadioHost' 'HandballPlayer' 'Cricketer' 'Jockey'\n",
      " 'SumoWrestler' 'AmericanFootballPlayer' 'LacrossePlayer' 'TennisPlayer'\n",
      " 'AmateurBoxer' 'SoccerPlayer' 'Rower' 'TableTennisPlayer'\n",
      " 'BeachVolleyballPlayer' 'SpeedwayRider' 'FormulaOneRacer' 'NascarDriver'\n",
      " 'Swimmer' 'IceHockeyPlayer' 'FigureSkater' 'Skater' 'Curler' 'Skier'\n",
      " 'GolfPlayer' 'SquashPlayer' 'PokerPlayer' 'BadmintonPlayer' 'ChessPlayer'\n",
      " 'RugbyPlayer' 'DartsPlayer' 'NetballPlayer' 'MartialArtist' 'Gymnast'\n",
      " 'Canoeist' 'GaelicGamesPlayer' 'HorseRider' 'BaseballPlayer' 'Cyclist'\n",
      " 'Bodybuilder' 'AustralianRulesFootballPlayer' 'BasketballPlayer'\n",
      " 'Ambassador' 'Baronet' 'Model' 'Architect' 'Judge' 'Economist'\n",
      " 'Journalist' 'Painter' 'Comedian' 'ComicsCreator' 'ClassicalMusicArtist'\n",
      " 'FashionDesigner' 'AdultActor' 'VoiceActor' 'Photographer' 'HorseTrainer'\n",
      " 'Entomologist' 'Medician' 'SoapCharacter' 'AnimangaCharacter'\n",
      " 'MythologicalFigure' 'Noble' 'Astronaut' 'OfficeHolder'\n",
      " 'PublicTransitSystem' 'BusCompany' 'LawFirm' 'Winery' 'RecordLabel'\n",
      " 'Brewery' 'Airline' 'Publisher' 'Bank' 'PoliticalParty' 'Legislature'\n",
      " 'Band' 'BasketballLeague' 'SoccerLeague' 'IceHockeyLeague'\n",
      " 'BaseballLeague' 'RugbyLeague' 'MilitaryUnit' 'University' 'School'\n",
      " 'CyclingTeam' 'CanadianFootballTeam' 'BasketballTeam'\n",
      " 'AustralianFootballTeam' 'HockeyTeam' 'HandballTeam' 'CricketTeam'\n",
      " 'RugbyClub' 'TradeUnion' 'RadioStation' 'BroadcastNetwork'\n",
      " 'TelevisionStation']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"Dataset\\DBP\\DBP_wiki_data.csv\", header=0)\n",
    "\n",
    "df2 = df.dropna()\n",
    "\n",
    "x2 = df2[\"text\"]\n",
    "y2 = df2['l3']\n",
    "\n",
    "list3 = str(df2['l3'].unique())\n",
    "\n",
    "print(x2[1])\n",
    "print(list3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba698e57",
   "metadata": {},
   "source": [
    "# Partie preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dca34",
   "metadata": {},
   "source": [
    "## 1 - Split des datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7440e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.2, random_state=42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c60d7",
   "metadata": {},
   "source": [
    "## 2 - Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9eb835",
   "metadata": {},
   "source": [
    "•\tNettoyage : Suppression url, emot, caractères spéciaux  \n",
    "•\tCorrection de la casse : Mettre tout en minuscule  \n",
    "•\tTokénisation : Découpage du texte en pièces  \n",
    "•\tLemmatisation : Supprimer uniqueùent les terminaisons inflexibles et donc à isoler la forme canonique du mot (lemme)  \n",
    "•\tSuppression des stop words : Enlever certains mots basiques prédéfinis  \n",
    "•\tStemming :supprimer suffixe et préfixes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a60d51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\USER/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward commercial private investment firm reputation make defense industry quietly another part market\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords, words\n",
    "import re\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "\n",
    "dictionnary = set(words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Donne la nature du mot (nom, verbe, adjectif, adverbe) pour la lemmatisation\n",
    "def get_wordnet_pos(word):\n",
    "  tag = pos_tag([word])[0][1][0].upper()\n",
    "  tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "  return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    # Suppression adresse mails et mot à un seul caractère\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.[A-Za-z]{2,7}\\b', '', text)\n",
    "    \n",
    "    # Séparation des phrases, suppression des espaces, mise en minuscule et suppression des chiffres\n",
    "    text = text.strip()\n",
    "    text= text.lower()\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "    \n",
    "    # Ponctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    tokenized = word_tokenize(text)\n",
    "\n",
    "    words_only = [word for word in tokenized if word.isalpha()]\n",
    "    good_words = [word for word in words_only if word in dictionnary]\n",
    "    without_stopwords = [word for word in good_words if not word in stop_words]\n",
    "\n",
    "    # Lemmatisation\n",
    "    lemmatized = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in without_stopwords]\n",
    "    cleaned_text = \" \".join(lemmatized)\n",
    "    return cleaned_text\n",
    "\n",
    "#Pour test rapide\n",
    "apres = preprocessing(x_train1[1])\n",
    "print(apres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39c63c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = x_train1.apply(preprocessing)\n",
    "x_test1 = x_test1.apply(preprocessing)\n",
    "x_train2 = x_train2.apply(preprocessing)\n",
    "x_test2 = x_test2.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a92db",
   "metadata": {},
   "source": [
    "## 3 - Création des datasets pour entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09cf83",
   "metadata": {},
   "source": [
    "### Enregistré dans le document Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019c754",
   "metadata": {},
   "source": [
    "#### Dataset AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65698d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediation resolve dispute fiat general corp fiat spa meet next four try resolve dispute whether fiat force buy ail fiat auto subsidiary\n",
      "3\n",
      "(102080,)\n",
      "(102080,)\n",
      "(25520,)\n",
      "(25520,)\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la structure des datasets\n",
    "print(x_train1.iloc[0])\n",
    "print(y_train1.iloc[0])\n",
    "\n",
    "print(x_train1.shape)\n",
    "print(y_train1.shape)\n",
    "\n",
    "print(x_test1.shape)\n",
    "print(y_test1.shape)\n",
    "\n",
    "x_train1.to_csv(r\"Dataset\\AG_classif\\x_train.csv\", index=False)\n",
    "y_train1.to_csv(r\"Dataset\\AG_classif\\y_train.csv\", index=False)\n",
    "x_test1.to_csv(r\"Dataset\\AG_classif\\x_test.csv\", index=False)\n",
    "y_test1.to_csv(r\"Dataset\\AG_classif\\y_test.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc847cce",
   "metadata": {},
   "source": [
    "#### Dataset DBP (wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "630d1087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "born former democratic congressman state colorado\n",
      "Congressman\n",
      "(274224,)\n",
      "(274224,)\n",
      "(68557,)\n",
      "(68557,)\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la structure des datasets\n",
    "print(x_train2.iloc[0])\n",
    "print(y_train2.iloc[0])\n",
    "\n",
    "print(x_train2.shape)\n",
    "print(y_train2.shape)\n",
    "\n",
    "print(x_test2.shape)\n",
    "print(y_test2.shape)\n",
    "\n",
    "x_train2.to_csv(r\"Dataset\\DBP\\x_train.csv\", index=False)\n",
    "y_train2.to_csv(r\"Dataset\\DBP\\y_train.csv\", index=False)\n",
    "x_test2.to_csv(r\"Dataset\\DBP\\x_test.csv\", index=False)\n",
    "y_test2.to_csv(r\"Dataset\\DBP\\y_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
